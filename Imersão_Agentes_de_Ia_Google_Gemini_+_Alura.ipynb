{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMwh6XSDIGtXGWowZNZLyxK"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Aula 1"
      ],
      "metadata": {
        "id": "csMP5DEthxkc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjXdvqUtaZLx",
        "outputId": "ad415201-a69b-448c-f619-3ae3df7b76a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q --upgrade langchain langchain-google-genai google-generativeai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importação da API Key"
      ],
      "metadata": {
        "id": "u6nViOkfqdp1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "GOOGLE_API_KEY = userdata.get('GEMINI_API_KEY')"
      ],
      "metadata": {
        "id": "wLhOCv1Ceccu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conexão com o Gemini"
      ],
      "metadata": {
        "id": "ERgMwMo7qe9p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lln = ChatGoogleGenerativeAI(\n",
        "    model='gemini-2.5-flash',\n",
        "    temperature=0,\n",
        "    api_key=GOOGLE_API_KEY\n",
        ")"
      ],
      "metadata": {
        "id": "6_xPNeymgSj2"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Teste básico do modelo com uma pergunta"
      ],
      "metadata": {
        "id": "fnzbrytGqgnc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resp_teste = lln.invoke('Quem é voce?')\n",
        "print(resp_teste.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mgZsVYsibFt",
        "outputId": "236a2fcf-c2c6-450e-c701-298a7cb63f5b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eu sou um modelo de linguagem grande, treinado pelo Google.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TRIAGEM_PROMPT = (\n",
        "    \"Você é um triador de Service Desk para políticas internas da empresa Carraro Desenvolvimento. \"\n",
        "    \"Dada a mensagem do usuário, retorne SOMENTE um JSON com:\\n\"\n",
        "    \"{\\n\"\n",
        "    '  \"decisao\": \"AUTO_RESOLVER\" | \"PEDIR_INFO\" | \"ABRIR_CHAMADO\",\\n'\n",
        "    '  \"urgencia\": \"BAIXA\" | \"MEDIA\" | \"ALTA\",\\n'\n",
        "    '  \"campos_faltantes\": [\"...\"]\\n'\n",
        "    \"}\\n\"\n",
        "    \"Regras:\\n\"\n",
        "    '- **AUTO_RESOLVER**: Perguntas claras sobre regras ou procedimentos descritos nas políticas (Ex: \"Posso reembolsar a internet do meu home office?\", \"Como funciona a política de alimentação em viagens?\").\\n'\n",
        "    '- **PEDIR_INFO**: Mensagens vagas ou que faltam informações para identificar o tema ou contexto (Ex: \"Preciso de ajuda com uma política\", \"Tenho uma dúvida geral\").\\n'\n",
        "    '- **ABRIR_CHAMADO**: Pedidos de exceção, liberação, aprovação ou acesso especial, ou quando o usuário explicitamente pede para abrir um chamado (Ex: \"Quero exceção para trabalhar 5 dias remoto.\", \"Solicito liberação para anexos externos.\", \"Por favor, abra um chamado para o RH.\").'\n",
        ")"
      ],
      "metadata": {
        "id": "cAmFf_KVjNZA"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definição do Modelo de Saída com Pydantic"
      ],
      "metadata": {
        "id": "ar_w7BtdqbBP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from typing import Literal, List, Dict\n",
        "\n",
        "class TriagemOut(BaseModel):\n",
        "  decisao: Literal['AUTO_RESOLVER', 'PEDIR_INFO', 'ABRIR_CHAMADO']\n",
        "  urgencia: Literal[\"BAIXA\", \"MEDIA\", \"ALTA\"]\n",
        "  campos_faltantes: List[str] = Field(default_factory=list)"
      ],
      "metadata": {
        "id": "piSiW1rWlAnz"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Criação do LLM para Classificação e da Chain"
      ],
      "metadata": {
        "id": "vvF2TROdqk7L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lln_triagem = ChatGoogleGenerativeAI (\n",
        "    model='gemini-2.5-flash',\n",
        "    temperature=0,\n",
        "    api_key=GOOGLE_API_KEY\n",
        ")"
      ],
      "metadata": {
        "id": "xZdJJIYlmBoa"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importa mensagens e cria a chain com saída estruturada."
      ],
      "metadata": {
        "id": "sboIyeHiqmm7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import SystemMessage, HumanMessage\n",
        "\n",
        "triagem_chain = lln_triagem.with_structured_output(TriagemOut)\n",
        "\n",
        "def triagem(mensagem : str) -> Dict:\n",
        "  saida: TriagemOut = triagem_chain.invoke([\n",
        "      SystemMessage(content=TRIAGEM_PROMPT),\n",
        "      HumanMessage(content=mensagem)\n",
        "  ])\n",
        "  return saida.model_dump()"
      ],
      "metadata": {
        "id": "0K8hPxg3mWut"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testes do Agente"
      ],
      "metadata": {
        "id": "Cwc2OUVCqoNV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "testes =  [\"Posso reembolsar a internet?\",\n",
        "           \"Quero ter mais 5 dias remoto, Como faco?\",\n",
        "           \"Posso reembolsar cursos ou treinamentos do Alura\",\n",
        "           \"Quantas capivaras tem no Rio Pinheiros?\"]\n",
        "\n",
        "for msg_teste in testes:\n",
        "  print(f\"Pergunta: {msg_teste}\\n -> Resposta: {triagem(msg_teste)}\\n\")"
      ],
      "metadata": {
        "id": "CN2WpRUkohGJ"
      },
      "execution_count": 18,
      "outputs": []
    }
  ]
}